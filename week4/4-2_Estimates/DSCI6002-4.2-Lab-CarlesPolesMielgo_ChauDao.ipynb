{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4.2: Point Estimation\n",
    "\n",
    "## Outline\n",
    " \n",
    "- Estimand, estimator and estimate\n",
    "- MLE and MOM\n",
    "- MSE of an estimator\n",
    "    * Bias\n",
    "    * Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**\n",
    "\n",
    "100 voters are polled before the election, and it was found that 55% are in favor of the Republican candidate.\n",
    "\n",
    "1. State the **estimand, estimator and estimate** of this study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimand: percentage of voters in favor of the Republican candidate.\n",
    "\n",
    "Estimator: (number of voters in favor of the Republican candidate/total voters) x 100\n",
    "\n",
    "Estimate: 55%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Let $X_1, \\dots, X_n$ be i.i.d. with PDF  \n",
    "\n",
    "$$ f(x | \\theta) = \\theta x^{\\theta - 1} \\text{, } 0 \\leq x \\leq 1 \\text{, } 0 < \\theta < \\infty $$\n",
    "\n",
    "Find the MLE of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P(x_i) = \\theta x_i^{\\theta - 1}$\n",
    "\n",
    "$L(x|\\theta) = \\sum_{i=1}^{n}P(x_i)$\n",
    "\n",
    "$l(x) = log(L(x|\\theta)) = log(\\prod_{i=1}^{n}P(x_i)) = log(\\prod_{i=1}^{n}\\theta x_i^{\\theta - 1} ) = \\sum_{i=1}^{n} log(\\theta x_i^{\\theta - 1}) = \\sum_{i=1}^{n} log(\\theta) + (\\theta - 1) * log(x_i)$\n",
    "\n",
    "$\\frac{dP}{d\\theta} = d(log(\\theta) + (\\theta - 1) * log(x_i)) = 1/(\\theta) + 1$\n",
    "\n",
    "If $\\frac{dP}{d\\theta} = 0$, then $\\theta = -1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**\n",
    "\n",
    "Let $X_1, \\dots, X_n$ be a random sample from a population with PMF\n",
    "\n",
    "$$ P(X = x) = \\theta^x (1 - \\theta)^{1 - x} \\text{, } x = 0 \\text{ or } 1 \\text{, } 0 \\leq \\theta \\leq \\frac{1}{2} $$  \n",
    "\n",
    "(a) Find the MOM estimator and MLE of $\\theta$.  \n",
    "\n",
    "(b) Find the mean squared errors (MSE) of each of the estimators.  \n",
    "\n",
    "(c) Which estimator is preferred? Justify your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a)\n",
    "\n",
    "MOM = $\\mu_n = \\operatorname{E}[(X-a)^n] = \\frac{1}{m}\\sum_{i=1}^m(x_i-a)^n$\n",
    "\n",
    "now, a = 0, and n = 1, so we get:\n",
    "\n",
    "$\\mu_n = \\operatorname{E}[(X)] = \\frac{1}{n}\\sum_{i=1}^n(x_i)$\n",
    "\n",
    "MLE\n",
    "\n",
    "$l(\\theta) = log(\\theta^x (1 - \\theta)^{1 - x}) = log(\\theta^x) + log((1-\\theta)^{1-x}) = x * log(\\theta) + (1-x) * log(1-\\theta)$\n",
    "\n",
    "Now, if we derivate above respect $\\theta$ we get:\n",
    "\n",
    "$ \\begin{align*}\n",
    "     \\frac{dl}{d\\theta} &= x (\\frac{1}{\\theta}) - (1-x) (\\frac{1}{1 - \\theta}) \\\\\n",
    "                   &= \\frac{x}{\\theta} - \\frac{1-x}{1 - \\theta}\n",
    "   \\end{align*} $\n",
    "   \n",
    "The maximizing value of $\\theta$ occurs when:\n",
    "\n",
    "$ \\frac{dl}{d\\theta} = 0 $\n",
    "\n",
    "This gives us : \n",
    "\n",
    "$ \\frac{dl}{d\\theta} = \\frac{x}{\\theta} - \\frac{1-x}{1 - \\theta} = 0 $\n",
    "\n",
    "$\\hat{\\theta} = \\frac{1}{n}$\n",
    "\n",
    "(b)\n",
    "\n",
    "MSE\n",
    "\n",
    "$ E(\\hat{\\theta} - \\theta)^2 = Var(\\hat{\\theta}) + [E(\\hat{\\theta}) - \\theta]^2 = Var(\\hat{\\theta}) + (Bias(\\hat{\\theta}))^2 $\n",
    "\n",
    "Now, MLE above is equal MOM which is $\\mu$ (the mean). By definition, the mean is unbias, so our formula for MSE is:\n",
    "\n",
    "$ E(\\hat{\\theta} - \\theta)^2 = Var(\\hat{\\theta})$\n",
    "\n",
    "$Var(\\hat{\\theta}) = \\operatorname{E}[(X-\\mu)^2] = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\mu)^2$\n",
    "\n",
    "(c)\n",
    "\n",
    "MOM and MLE are the same in this case. MOM is much simpler to calculate compared to MLE, and since results are the same, I prefer MOM per simplicity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4**\n",
    "\n",
    "Three independent groups conducted their own polls to estimate the percentage of voters favor the Republican candidate:\n",
    "- Group 1 and Group 2 randomly polled people from the US population \n",
    "- Group 3 polled people by asking passer-bys at the the corner of a street in Texas, Austin\n",
    "\n",
    "The percentage that favors the Republican candidate in each of the polls are as follows:\n",
    "- Group 1: 49.27%\n",
    "- Group 2: 48.904%\n",
    "- Group 3: 70%\n",
    "\n",
    "\n",
    "1. Which group(s) is likely to have a larger bias? Why?\n",
    "2. Do you know the true bias? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The group with larger bias is group 3 because shows a percentage that favors the Republican candidate very different from the other 2 groups. Besides, the methodology used by Group 3 introduced bias since we are asking people in Texas, a known red state (sample bias). The other 2 groups collect data randomly across the entire US population, which reduces significantly the bias (group 3 collects data from just people passing by one street of one town of one state of the US).\n",
    "\n",
    "2. $Bias(\\hat{\\theta}) = E(\\hat{\\theta}) - \\theta$.\n",
    "\n",
    "If we take as expected value $\\hat{\\theta}$ = (49.27 + 48.904)/2 = 49.087\n",
    "\n",
    "$\\theta$ = 70, then:\n",
    "\n",
    "$Bias(\\hat{\\theta}) = -20.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5** (Extra Credit)\n",
    "\n",
    "Suppose $X_1, \\dots, X_n$ are i.i.d. $N(\\mu, \\sigma^2)$. From today's class, we know that the sample mean ($\\bar{X}$) and variance ($S^2$) are unbiased estimators of the population mean ($\\mu$) and variance ($\\sigma^2$),  \n",
    "\n",
    "$$ E(\\bar{X}) = \\mu $$  \n",
    "\n",
    "\n",
    "$$ E(S^2) = \\sigma^2 $$  \n",
    "\n",
    "The MLE of $\\mu$ and $\\sigma^2$ are:  \n",
    "\n",
    "$$ \\hat{\\mu} = \\bar{X} $$  \n",
    "\n",
    "\n",
    "$$ \\hat{\\sigma}^2 = \\frac{1}{n} \\sum X_i^2 - \\bar{X}^2 = \\frac{1}{n} \\sum (X_i - \\bar{X})^2 $$  \n",
    "\n",
    "(a) Are the MLE's above unbiased estimators? Why or why not?  \n",
    "\n",
    "(b) Find the mean squared errors (MSE) of the MLE estimators. (Hint: the MSE part of the lecture notes may help) \n",
    "\n",
    "(c) Write a function in Python to randomly draw 100 values from a $N(0, 1)$ distribution.\n",
    "\n",
    "(d) Use the function above to draw 1000 samples, each with 100 values in it.  \n",
    "\n",
    "(e) For each sample:  \n",
    "\n",
    "    (1) Estimate the variance using sample variance  \n",
    "    \n",
    "    (2) Estimate the variance using the MLE\n",
    "\n",
    "(f) Plot a histogram of the sample variances, and a histogram of the MLE's for the variance\n",
    "\n",
    "(g) Compare the two histograms, what do you notice? Do they estimate the true variance accurately on average? (Hint: it may help to add a vertical line at the value of the true variance on the histograms)\n",
    "\n",
    "(h) Which estimator is preferred, the sample variance or the MLE? Why?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# c\n",
    "import numpy as np\n",
    "def draw_normal(size, mu, sigma):\n",
    "    sample = np.random.normal(mu, sigma, size)\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "draw_normal(100, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
